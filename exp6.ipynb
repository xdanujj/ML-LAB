{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gK7yWuf3fP9b",
        "outputId": "491e9ff4-51c4-4611-e3c4-4fb7f21e77bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression:\n",
            "  Mean Accuracy: 0.9733\n",
            "  Bias (Training Error): 0.0250\n",
            "  Variance (Test Error Mean): 0.0267\n",
            "  Variance of Test Errors: 0.0249\n",
            "\n",
            "Decision Tree:\n",
            "  Mean Accuracy: 0.9533\n",
            "  Bias (Training Error): 0.0033\n",
            "  Variance (Test Error Mean): 0.0467\n",
            "  Variance of Test Errors: 0.0267\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Define models\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(max_iter=200),\n",
        "    'Decision Tree': DecisionTreeClassifier(max_depth=5, random_state=42)\n",
        "}\n",
        "\n",
        "# K-Fold setup\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Perform K-Fold CV and calculate bias-variance\n",
        "for model_name, model in models.items():\n",
        "    train_errors = []\n",
        "    test_errors = []\n",
        "\n",
        "    for train_idx, test_idx in kf.split(X):\n",
        "        X_train, X_test = X[train_idx], X[test_idx]\n",
        "        y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Training and validation error\n",
        "        train_errors.append(1 - model.score(X_train, y_train))\n",
        "        test_errors.append(1 - model.score(X_test, y_test))\n",
        "\n",
        "    mean_train_error = np.mean(train_errors)\n",
        "    mean_test_error = np.mean(test_errors)\n",
        "    std_test_error = np.std(test_errors)\n",
        "    mean_accuracy = 1 - mean_test_error\n",
        "\n",
        "    print(f\"{model_name}:\")\n",
        "    print(f\"  Mean Accuracy: {mean_accuracy:.4f}\")\n",
        "    print(f\"  Bias (Training Error): {mean_train_error:.4f}\")\n",
        "    print(f\"  Variance (Test Error Mean): {mean_test_error:.4f}\")\n",
        "    print(f\"  Variance of Test Errors: {std_test_error:.4f}\\n\")"
      ]
    }
  ]
}